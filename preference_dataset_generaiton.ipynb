{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_wTvhWjS1_4"
      },
      "source": [
        "# Introduction\n",
        "This script is served for preference datasete generation for RLHF algorithm, including code summary task and code generation task. In this code, Gemini Pro model out is treated as the chosen one and Phi-2 model output is treated as the rejected one. Before start, please download the [leetcode dataset](https://huggingface.co/datasets/RayBernard/leetcode/tree/main) and store it in a \"leetcode\" folder.\n",
        "\n",
        "\n",
        "Reference: [tutorial for Genemi API.ipynb](https://github.com/DylanJamesZapzalka/eecs-545-project/blob/main/tutorial%20for%20Genemi%20API.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKyDV8YlBuY8"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC3c4ROnBocv"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8x1wPnITvkT"
      },
      "source": [
        "## Gemini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJwDFs3BTB7G",
        "outputId": "627b98b9-1c17-4b75-b0ec-d614d9e18f37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/137.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P8kpK-xTIPM"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup your API key\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "[Get an API key](https://aistudio.google.com/app/apikey)\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"🔑\" in the left panel. Give it the name GOOGLE_API_KEY.\n",
        "\n",
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "Put the key in the GOOGLE_API_KEY environment variable (the SDK will automatically pick it up from there).\n",
        "Pass the key to genai.configure(api_key=...)"
      ],
      "metadata": {
        "id": "BhPuC2Tb9_x_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-ZFVfAwTLgx"
      },
      "outputs": [],
      "source": [
        "# You should configure your API_KEY see\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "KY8hCm6DTPbi",
        "outputId": "3745b7f3-18b8-4950-cb1e-432c1169ae4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dx46X4pITTGo"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.0-pro-latest')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code summary"
      ],
      "metadata": {
        "id": "rwxOjTSg71_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "dD6wcUd4B_MJ",
        "outputId": "1d35f3df-9bce-4d1c-815d-e1a5e476023e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'```python\\ndef twoSum(nums, target):\\n    map = {}\\n    for i, num in enumerate(nums):\\n        complement = target - num\\n        if complement in map:\\n            return [map[complement], i]\\n        map[num] = i\\n    return []\\n```\\n\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_file =  '/content/leetcode/'\n",
        "dataset = load_dataset(data_file)\n",
        "Python_problems = dataset[\"train\"]['output']  ## Python code\n",
        "preferred_summary = []\n",
        "Python_problems[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sr4cJmCwkAOa"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_index = len(preferred_summary)\n",
        "for i in range(start_index, len(Python_problems)):\n",
        "  prompt = \"Given the following Python code, provide a summary of its functionality:\\n\" + Python_problems[i]\n",
        "  try: # prevent from stream limitation\n",
        "    response = model.generate_content(prompt)\n",
        "  except:\n",
        "    time.sleep(5)\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "  try: # prevent from unsuccesful completion\n",
        "    code_summary = response.text\n",
        "    preferred_summary.append(code_summary)\n",
        "  except:\n",
        "    preferred_summary.append(\"\")\n",
        "\n",
        "  print(i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5QtF-1-gJbM",
        "outputId": "564e219c-e896-4987-fad3-20b531dd84ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2359"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(preferred_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code generation"
      ],
      "metadata": {
        "id": "67ORjzMk8PZl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file =  '/content/leetcode/'\n",
        "dataset = load_dataset(data_file)\n",
        "Python_problems = dataset[\"train\"]['input']  ## Python problem description\n",
        "preferred_solution = []\n",
        "Python_problems[0]"
      ],
      "metadata": {
        "id": "B74XskuE8OLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_index = len(preferred_solution)\n",
        "for i in range(start_index, len(Python_problems)):\n",
        "  prompt = \"### Indtruction:\\n Write a Python function that solves the following problem. Your function should take appropriate input (if any) and return the expected output. Feel free to provide any additional context or constraints necessary for solving the problem.\\n\" + \"### Question \\n\" + Python_problems[i]\n",
        "  try: # prevent from stream limitation\n",
        "    response = model.generate_content(prompt)\n",
        "  except:\n",
        "    time.sleep(5)\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "  try: # prevent from unsuccesful completion\n",
        "    code_summary = response.text\n",
        "    preferred_solution.append(code_summary)\n",
        "  except:\n",
        "    preferred_solution.append(\"\")\n",
        "\n",
        "  print(i)\n"
      ],
      "metadata": {
        "id": "oZUf5ugi8RuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKYnsLpRdeGA"
      },
      "source": [
        "## Phi-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2aaQyyRe6S5"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "d234a8ed0ad342a3a0bdae3be7be72db",
            "ccb591f2d3ee468e8dbb0908e969ef68",
            "dabeaa4036d841fbb7ec47a54c19ae6b",
            "a2d2f842929948d3aeb8f32ea36590ad",
            "0c574e1a6989499ead1935f9debce367",
            "e1dbe15b39654a9dad3da272e5fdb236",
            "5ec7e3d706b44232b540e0b9ca70cec2",
            "9018bcd922d9486bbb7045b40b3e171f",
            "a6ce760798bb4ba9920be5bd538eb72f",
            "48c21535e0964b21b44d08fee6641c24",
            "49f2982520594e76aabe004db9884c68"
          ]
        },
        "id": "J3Uu-sqXfLGe",
        "outputId": "3e7d9efb-70bb-4200-e46c-d4041c784396"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d234a8ed0ad342a3a0bdae3be7be72db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# torch.cuda.empty_cache()\n",
        "torch.set_default_device(\"cuda\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code summary"
      ],
      "metadata": {
        "id": "gj4fCYC9-Lub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file =  '/content/leetcode/'\n",
        "dataset = load_dataset(data_file)\n",
        "Python_problems = dataset[\"train\"]['output']  ## Python code\n",
        "to_markdowm(Python_problems[0])"
      ],
      "metadata": {
        "id": "uLwDnXlz-OVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNZ6kjt9i95d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "preferred_summary = []\n",
        "start_index = len(preferred_summary)\n",
        "for i in range(start_index, len(Python_problems)):\n",
        "  prompt = \"Given the following Python code, provide a summary of its functionality:\\n\" + Python_problems[i]\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False).to('cuda')\n",
        "\n",
        "  outputs = model.generate(**inputs, max_length=len(prompt)+300, pad_token_id=tokenizer.eos_token_id)\n",
        "  text = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "  rejected_summary.append(text)\n",
        "\n",
        "  print(i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Generation"
      ],
      "metadata": {
        "id": "XNiWZGJT_lec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_file =  '/content/leetcode/'\n",
        "dataset = load_dataset(data_file)\n",
        "Python_problems = dataset[\"train\"]['input']  ## Python problem description\n",
        "to_markdowm(Python_problems[0])"
      ],
      "metadata": {
        "id": "hMvlLTI-_qy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODeTYBpDe8yw"
      },
      "outputs": [],
      "source": [
        "rejected_solution = []\n",
        "for i in range(len(Python_problems)):\n",
        "  prompt = \"Write a Python function that solves the following problem. Your function should take appropriate input (if any) and return the expected output. Feel free to provide any additional context or constraints necessary for solving the problem.\\n\" + \"### Question \\n\" + Python_problems[i]\n",
        "  inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "  outputs = model.generate(**inputs, max_length=500, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "  text = tokenizer.batch_decode(outputs)[0]\n",
        "\n",
        "  rejected_solution.append(text)\n",
        "\n",
        "  print(i)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "c8x1wPnITvkT",
        "rwxOjTSg71_s",
        "SKYnsLpRdeGA",
        "gj4fCYC9-Lub",
        "XNiWZGJT_lec"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c574e1a6989499ead1935f9debce367": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48c21535e0964b21b44d08fee6641c24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f2982520594e76aabe004db9884c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ec7e3d706b44232b540e0b9ca70cec2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9018bcd922d9486bbb7045b40b3e171f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2d2f842929948d3aeb8f32ea36590ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48c21535e0964b21b44d08fee6641c24",
            "placeholder": "​",
            "style": "IPY_MODEL_49f2982520594e76aabe004db9884c68",
            "value": " 2/2 [00:03&lt;00:00,  1.43s/it]"
          }
        },
        "a6ce760798bb4ba9920be5bd538eb72f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ccb591f2d3ee468e8dbb0908e969ef68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1dbe15b39654a9dad3da272e5fdb236",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec7e3d706b44232b540e0b9ca70cec2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d234a8ed0ad342a3a0bdae3be7be72db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccb591f2d3ee468e8dbb0908e969ef68",
              "IPY_MODEL_dabeaa4036d841fbb7ec47a54c19ae6b",
              "IPY_MODEL_a2d2f842929948d3aeb8f32ea36590ad"
            ],
            "layout": "IPY_MODEL_0c574e1a6989499ead1935f9debce367"
          }
        },
        "dabeaa4036d841fbb7ec47a54c19ae6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9018bcd922d9486bbb7045b40b3e171f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6ce760798bb4ba9920be5bd538eb72f",
            "value": 2
          }
        },
        "e1dbe15b39654a9dad3da272e5fdb236": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}